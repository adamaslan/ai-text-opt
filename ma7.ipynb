{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample request: How can we improve emotional intimacy in our relationship?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 12:08:39,794 - INFO - Generated response: To improve emotional intimacy in your relationship, you and your partner need to share deep feelings, thoughts, and experiences with each other. This requires open communication, vulnerability, and a ...\n",
      "2025-02-21 12:08:39,799 - INFO - Context Analysis: To improve emotional intimacy in your relationship, you and your partner need to share deep feelings, thoughts, and experiences with each other. This requires open communication, vulnerability, and a ...\n",
      "2025-02-21 12:08:39,800 - ERROR - Processing failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Object:\n",
      "- Text: System Error: Expecting value: line 1 column 1 (char 0)...\n",
      "Error: True\n",
      "Duration: 0.00s\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "### COMPLETE IMPLEMENTATION ###\n",
    "##############################\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "import pickle\n",
    "import hashlib\n",
    "import tempfile\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ======================\n",
    "# CORE DATA STRUCTURES\n",
    "# ======================\n",
    "@dataclass\n",
    "class TherapeuticResponse:\n",
    "    VERSION = 2\n",
    "    text: str\n",
    "    timestamp: float\n",
    "    error: bool = False\n",
    "    processing_time: float = 0.0\n",
    "    error_details: str = \"\"\n",
    "    timeout: bool = False\n",
    "    empathy_score: float = 0.0\n",
    "    safety_checks: List[str] = None\n",
    "    ethical_considerations: List[str] = None\n",
    "    refinement_suggestions: List[str] = None\n",
    "    crisis_flag: bool = False\n",
    "    context_hash: str = \"\"\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = asdict(self)\n",
    "        state['_version'] = self.VERSION\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if state.get('_version', 1) < self.VERSION:\n",
    "            state.setdefault('context_hash', \"\")\n",
    "        self.__dict__.update(state)\n",
    "\n",
    "# ======================\n",
    "# UTILITIES\n",
    "# ======================\n",
    "class AtomicPickler:\n",
    "    @staticmethod\n",
    "    def save(obj, path):\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(mode='wb', delete=False, dir=os.path.dirname(path)) as tmp:\n",
    "                pickle.dump(obj, tmp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                os.replace(tmp.name, path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Atomic save failed: {str(e)}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Loading failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# ======================\n",
    "# CORE COMPONENTS\n",
    "# ======================\n",
    "class OllamaClient:\n",
    "    def __init__(self, model_name: str = \"hf.co/TheDrummer/Gemmasutra-Mini-2B-v1-GGUF:Q3_K_L\", base_url: str = \"http://localhost:11434\"):\n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url\n",
    "        self.max_retries = 5\n",
    "        self.request_timeout = 600  # Increased timeout\n",
    "        self._session = requests.Session()\n",
    "\n",
    "    def _parse_json_safe(self, text: str):\n",
    "        clean_text = text.strip()\n",
    "        try:\n",
    "            return json.loads(clean_text)\n",
    "        except json.JSONDecodeError:\n",
    "            start = clean_text.find('{')\n",
    "            end = clean_text.rfind('}') + 1\n",
    "            return json.loads(clean_text[start:end])\n",
    "        except:\n",
    "            return {\"error\": \"Invalid JSON format\"}\n",
    "\n",
    "    def generate(self, prompt: str) -> Tuple[str, bool]:\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = self._session.post(\n",
    "                    f\"{self.base_url}/api/generate\",\n",
    "                    json={\n",
    "                        \"model\": self.model_name,\n",
    "                        \"prompt\": prompt[:4000],\n",
    "                        \"stream\": False,\n",
    "                        \"options\": {\"temperature\": 0.5}\n",
    "                    },\n",
    "                    timeout=self.request_timeout\n",
    "                )\n",
    "                data = self._parse_json_safe(response.text)\n",
    "                return data.get(\"response\", \"\"), False\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt+1} failed: {e}\")\n",
    "                time.sleep(2 ** attempt)\n",
    "        return f\"Error: Failed after {self.max_retries} attempts\", True\n",
    "\n",
    "class BaseAgent:\n",
    "    def __init__(self, client: OllamaClient):\n",
    "        self.client = client\n",
    "        self.retry_count = 3\n",
    "        self.max_wait = 600  # Increased timeout\n",
    "        self._state_dir = \"agent_states\"\n",
    "        os.makedirs(self._state_dir, exist_ok=True)\n",
    "\n",
    "    def safe_generate(self, prompt: str) -> TherapeuticResponse:\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            text, error = self.client.generate(prompt)\n",
    "            logger.info(f\"Generated response: {text[:200]}...\")\n",
    "            return TherapeuticResponse(\n",
    "                text=text,\n",
    "                timestamp=start_time,\n",
    "                error=error,\n",
    "                processing_time=time.time() - start_time\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return TherapeuticResponse(\n",
    "                text=f\"Error: {str(e)}\",\n",
    "                timestamp=start_time,\n",
    "                error=True,\n",
    "                processing_time=time.time() - start_time\n",
    "            )\n",
    "\n",
    "class IntimacyActionGenerator(BaseAgent):\n",
    "    def generate_actions(self, analysis: Dict) -> List[Dict]:\n",
    "        prompt = f\"\"\"Generate intimacy-enhancing actions based on:\n",
    "        {json.dumps(analysis, indent=2)[:2000]}\n",
    "        Focus on mutual consent and emotional connection.\"\"\"\n",
    "        \n",
    "        response = self.safe_generate(prompt)\n",
    "        logger.info(f\"Action Generation Response: {response.text[:200]}...\")\n",
    "        return self.client._parse_json_safe(response.text).get('actions', [])\n",
    "\n",
    "class TherapeuticResponseSystem:\n",
    "    def __init__(self):\n",
    "        self.client = OllamaClient()\n",
    "        self.agents = {\n",
    "            'generator': IntimacyActionGenerator(self.client),\n",
    "            'context': BaseAgent(self.client),\n",
    "            'safety': BaseAgent(self.client)\n",
    "        }\n",
    "        self.history = []\n",
    "\n",
    "    def process_request(self, input_text: str) -> TherapeuticResponse:\n",
    "        try:\n",
    "            # Context analysis\n",
    "            context = self.agents['context'].safe_generate(f\"Analyze: {input_text}\")\n",
    "            logger.info(f\"Context Analysis: {context.text[:200]}...\")\n",
    "            \n",
    "            # Action generation\n",
    "            analysis = self.client._parse_json_safe(context.text)\n",
    "            actions = self.agents['generator'].generate_actions(analysis)\n",
    "            \n",
    "            # Safety check\n",
    "            safety_check = self.agents['safety'].safe_generate(\n",
    "                f\"Validate safety of: {json.dumps(actions)}\"\n",
    "            )\n",
    "            logger.info(f\"Safety Check: {safety_check.text[:200]}...\")\n",
    "            \n",
    "            # Build response\n",
    "            response = TherapeuticResponse(\n",
    "                text=json.dumps(actions),\n",
    "                timestamp=time.time(),\n",
    "                context_hash=hashlib.sha256(input_text.encode()).hexdigest()\n",
    "            )\n",
    "            \n",
    "            # Save outputs\n",
    "            AtomicPickler.save(response, \"last_response.pkl\")\n",
    "            logger.info(\"Response saved to last_response.pkl\")\n",
    "            \n",
    "            print(f\"\\nFinal Response:\\n{response.text}\")\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Processing failed: {str(e)}\")\n",
    "            return TherapeuticResponse(\n",
    "                text=f\"System Error: {str(e)}\",\n",
    "                timestamp=time.time(),\n",
    "                error=True\n",
    "            )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    system = TherapeuticResponseSystem()\n",
    "    sample_input = \"How can we improve emotional intimacy in our relationship?\"\n",
    "    print(f\"Processing sample request: {sample_input}\")\n",
    "    response = system.process_request(sample_input)\n",
    "    print(\"\\nResponse Object:\")\n",
    "    print(f\"- Text: {response.text[:200]}...\")\n",
    "    print(f\"Error: {response.error}\")\n",
    "    print(f\"Duration: {response.processing_time:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
