{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (0.3.14)\n",
      "Requirement already satisfied: huggingface_hub in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (0.26.2)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (0.42.0)\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (3.11.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from bitsandbytes) (1.12.0)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.115.11)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Using cached gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.27.2)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (3.10.14)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (11.0.0)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.9.9)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.46.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from gradio-client==1.8.0->gradio) (15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/46.9 MB\u001b[0m \u001b[31m266.2 kB/s\u001b[0m eta \u001b[36m0:02:34\u001b[0m"
     ]
    }
   ],
   "source": [
    "# works responses not great - better rag needed\n",
    "# Install required packages\n",
    "!pip install langchain huggingface_hub pandas faiss-cpu numpy transformers torch accelerate bitsandbytes gradio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "def load_embeddings(csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Verify required columns exist\n",
    "        if 'Cleaned_Ideas' not in df.columns or 'Embeddings' not in df.columns:\n",
    "            raise ValueError(\"CSV must contain 'Cleaned_Ideas' and 'Embeddings' columns\")\n",
    "            \n",
    "        # Convert embeddings with proper handling\n",
    "        df['Embeddings'] = df['Embeddings'].apply(\n",
    "            lambda x: np.fromstring(\n",
    "                x.strip(\"[]\").replace(\"\\n\", \"\"),\n",
    "                sep=\", \",\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Validate embedding dimensions (RoBERTa-base has 768 dimensions)\n",
    "        expected_dim = 768\n",
    "        valid_embeddings = df['Embeddings'].apply(lambda x: len(x) == expected_dim)\n",
    "        if not valid_embeddings.all():\n",
    "            invalid_count = len(df) - valid_embeddings.sum()\n",
    "            raise ValueError(f\"{invalid_count} entries have invalid embedding dimensions\")\n",
    "            \n",
    "        return df['Cleaned_Ideas'].tolist(), np.array(df['Embeddings'].tolist())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embeddings: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 1. Load texts and embeddings from CSV\n",
    "texts, embeddings = load_embeddings(\"ideas_with_embeddings.csv\")\n",
    "\n",
    "# 2. Create FAISS vector store using a Hugging Face embedding model (using roberta-base)\n",
    "try:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=\"roberta-base\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        # Removed \"show_progress_bar\" to avoid duplicate parameter issues.\n",
    "        encode_kwargs={'normalize_embeddings': False}\n",
    "    )\n",
    "    \n",
    "    # Create FAISS index; each entry is a tuple (text, embedding)\n",
    "    vector_store = FAISS.from_embeddings(\n",
    "        text_embeddings=list(zip(texts, embeddings)),\n",
    "        embedding=embedding_model,\n",
    "        normalize_L2=True  # Improves cosine similarity calculations\n",
    "    )\n",
    "    print(f\"FAISS index created with {vector_store.index.ntotal} entries\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Vector store creation failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# 3. Load a smaller Hugging Face model in safetensors format (EleutherAI/gpt-neo-125M)\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "try:\n",
    "    # For a smaller model, we typically use full precision\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"GPT-Neo 125M model loaded successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Model loading failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create the text-generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    do_sample=True,\n",
    "    return_full_text=False,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 4. Define a custom prompt template\n",
    "template = \"\"\"### Instruction:\n",
    "Analyze this philosophical concept using the provided context. \n",
    "If unsure, state \"I don't have sufficient information.\"\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template_format=\"f-string\"\n",
    ")\n",
    "\n",
    "# 5. Set up a Production-grade Retrieval QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5, \"score_threshold\": 0.4}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt,\n",
    "        \"document_prompt\": PromptTemplate(\n",
    "            input_variables=[\"page_content\"],\n",
    "            template=\"{page_content}\"\n",
    "        )\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 6. Function to process queries for Gradio interface\n",
    "def process_query(query):\n",
    "    if not query.strip():\n",
    "        return \"Please enter a valid question\", \"\"\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain({\"query\": query})\n",
    "        \n",
    "        # Process the response\n",
    "        response = result['result'].split(\"### Response:\")[-1].strip()\n",
    "        \n",
    "        # Format source information\n",
    "        sources_info = \"\\n\\n**Sources:**\\n\"\n",
    "        for i, doc in enumerate(result['source_documents'][:3], 1):\n",
    "            excerpt = doc.page_content[:150].replace(\"\\n\", \" \") + \"...\"\n",
    "            score = doc.metadata.get('score', 0)\n",
    "            sources_info += f\"{i}. {excerpt} (Score: {score:.2f})\\n\\n\"\n",
    "            \n",
    "        return response, sources_info\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error processing request: {str(e)}\", \"\"\n",
    "\n",
    "# 7. Create Gradio interface\n",
    "def create_gradio_interface():\n",
    "    with gr.Blocks(title=\"Philosophical Concepts RAG\") as demo:\n",
    "        gr.Markdown(\"# Philosophical Concepts RAG System\")\n",
    "        gr.Markdown(\"Ask questions about philosophical concepts and get answers based on the knowledge base.\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=4):\n",
    "                query_input = gr.Textbox(\n",
    "                    label=\"Your Question\",\n",
    "                    placeholder=\"Enter your philosophical question here...\",\n",
    "                    lines=2\n",
    "                )\n",
    "                submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "            \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                response_output = gr.Markdown(label=\"Response\")\n",
    "            with gr.Column(scale=2):\n",
    "                sources_output = gr.Markdown(label=\"Sources\")\n",
    "                \n",
    "        submit_btn.click(\n",
    "            fn=process_query,\n",
    "            inputs=[query_input],\n",
    "            outputs=[response_output, sources_output]\n",
    "        )\n",
    "        \n",
    "        gr.Markdown(\"## Examples\")\n",
    "        examples = gr.Examples(\n",
    "            examples=[\n",
    "                [\"What is the concept of dualism?\"],\n",
    "                [\"Explain Kant's categorical imperative.\"],\n",
    "                [\"How does existentialism view freedom?\"]\n",
    "            ],\n",
    "            inputs=query_input\n",
    "        )\n",
    "        \n",
    "    return demo\n",
    "\n",
    "# 8. Run the chat interface with Gradio\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch(share=True)  # share=True creates a public link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
