{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Core Components\n",
    "from typing import List\n",
    "import logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import subprocess\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ======== Retrieval Component ========\n",
    "class RetrievalComponent:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.documents = []\n",
    "        self.index = None\n",
    "        self.retriever = None\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self._init_retriever()\n",
    "\n",
    "    def _init_retriever(self):\n",
    "        self.retriever = SentenceTransformer(self.config['retriever_model'])\n",
    "\n",
    "    def load_knowledge_base(self, file_path: str):\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                self.documents = [line.strip() for line in f if line.strip()]\n",
    "            \n",
    "            embeddings = self.retriever.encode(self.documents)\n",
    "            self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "            self.index.add(embeddings.astype('float32'))\n",
    "            self.logger.info(f\"Loaded {len(self.documents)} documents\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Knowledge base error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 3) -> List[str]:\n",
    "        try:\n",
    "            query_embed = self.retriever.encode([query])\n",
    "            _, indices = self.index.search(query_embed.astype('float32'), k)\n",
    "            return [self.documents[i] for i in indices[0]]\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Retrieval error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# ======== Generation Component ========\n",
    "class GenerationComponent:\n",
    "    HISTORY_FILE = \"ollama_rag_history.pkl\"\n",
    "    \n",
    "    def __init__(self, config, retriever: RetrievalComponent):\n",
    "        self.config = config\n",
    "        self.retriever = retriever\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def _run_ollama(self, prompt: str) -> str:\n",
    "        response_data = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model': self.config['model_name'],\n",
    "            'prompt': prompt,\n",
    "            'response': '',\n",
    "            'execution_time': 0,\n",
    "            'context': []\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            process = subprocess.run(\n",
    "                [\"ollama\", \"run\", self.config['model_name']],\n",
    "                input=prompt,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=self.config.get('timeout', 60)\n",
    "            )\n",
    "\n",
    "            response = process.stdout.strip()\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            response_data.update({\n",
    "                'response': response,\n",
    "                'execution_time': round(elapsed_time, 2),\n",
    "                'context': self.retriever.retrieve(prompt)\n",
    "            })\n",
    "\n",
    "            self._save_history(response_data)\n",
    "            return response\n",
    "\n",
    "        except subprocess.TimeoutExpired:\n",
    "            response_data['response'] = \"Error: Response timed out.\"\n",
    "            self._save_history(response_data)\n",
    "            return response_data['response']\n",
    "\n",
    "    def _save_history(self, response_data: dict):\n",
    "        try:\n",
    "            history = {'interactions': []}\n",
    "            if os.path.exists(self.HISTORY_FILE):\n",
    "                with open(self.HISTORY_FILE, \"rb\") as f:\n",
    "                    history = pickle.load(f)\n",
    "            \n",
    "            history['interactions'].append(response_data)\n",
    "            \n",
    "            with open(self.HISTORY_FILE, \"wb\") as f:\n",
    "                pickle.dump(history, f)\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"History save error: {str(e)}\")\n",
    "\n",
    "    def rag_generate(self, query: str) -> str:\n",
    "        try:\n",
    "            context = self.retriever.retrieve(query)\n",
    "            prompt = f\"Context: {' '.join(context)}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "            return self._run_ollama(prompt)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Generation error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def show_history(self):\n",
    "        try:\n",
    "            with open(self.HISTORY_FILE, \"rb\") as f:\n",
    "                history = pickle.load(f)\n",
    "                print(f\"\\n{'='*40}\\nRAG Interaction History\")\n",
    "                for idx, interaction in enumerate(history['interactions'], 1):\n",
    "                    print(f\"\\nInteraction {idx} ({interaction['timestamp']}):\")\n",
    "                    print(f\"Model: {interaction['model']}\")\n",
    "                    print(f\"Context: {interaction['context'][:2]}...\")\n",
    "                    print(f\"Prompt: {interaction['prompt'][:100]}...\")\n",
    "                    print(f\"Response: {interaction['response'][:200]}...\")\n",
    "                    print(f\"Execution time: {interaction['execution_time']}s\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No history available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knowledge base error: [Errno 2] No such file or directory: 'knowledge_base.txt'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'knowledge_base.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize components\u001b[39;00m\n\u001b[1;32m     12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m RetrievalComponent(config)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_knowledge_base\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mknowledge_base.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with actual path\u001b[39;00m\n\u001b[1;32m     15\u001b[0m generator \u001b[38;5;241m=\u001b[39m GenerationComponent(config, retriever)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Example interaction\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36mRetrievalComponent.load_knowledge_base\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_knowledge_base\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[1;32m     30\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'knowledge_base.txt'"
     ]
    }
   ],
   "source": [
    "# Cell 2: Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'model_name': \"hf.co/TheDrummer/Gemmasutra-Mini-2B-v1-GGUF:Q3_K_L\",\n",
    "        'retriever_model': \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        'timeout': 90,\n",
    "        'max_context_items': 3\n",
    "    }\n",
    "\n",
    "    # Initialize components\n",
    "    retriever = RetrievalComponent(config)\n",
    "    retriever.load_knowledge_base(\"knowledge_base.txt\")  # Replace with actual path\n",
    "    \n",
    "    generator = GenerationComponent(config, retriever)\n",
    "\n",
    "    # Example interaction\n",
    "    query = \"Explain the benefits of running models locally.\"\n",
    "    response = generator.rag_generate(query)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Response: {response[:500]}...\")  # Show first 500 characters\n",
    "\n",
    "    # Display history\n",
    "    print(\"\\n=== Interaction History ===\")\n",
    "    generator.show_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
