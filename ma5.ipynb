{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved to therapeutic_response.pkl\n",
      "TherapeuticResponse(text=\"Some great vibes to help turn a bad boy into a good one:\\n\\n1. Hugs and kisses - Give him lots of affectionate cuddles and smooches, especially when he least expects it. A surprise kiss on the cheek can really brighten his day. \\n\\n2. Compliments - Let him know how amazing he looks or what an incredible job he did today. Even if you're joking, praise is always a good vibe booster for bad boys.\\n\\n3. Laughter - Crack jokes and have silly conversations with him. Humor helps break the ice and shows his goofy side. \\n\\n4. Quality time - Take him to do something fun together like mini golf or bowling. Or just chill and watch a movie on the couch. Intimate bonding moments are key.\\n\\n5. Affirmations - Tell him how much you love and appreciate him over and over again. Bad boys need constant reassurance of their value. \\n\\n6. Treats - Surprise him with little gifts, like his favorite candy or cool socks. Small gestures go a long way in boosting his spirits.\\n\\n7. Dirty talk - Let him know what he does to you when he's naughty. Express how turned on he makes you and how much you want him. \\n\\n8. Gentle touches - Brush his hair off his neck, caress his chest or hand under his shirt. Sensual caresses are a great way to flirt with bad boys.\\n\\n9. Dirty jokes - Tell him dirty stories that make him laugh until he cries. Bad boys love their dirty humor! It's a special kind of naughty.\\n\\n10. Foot rubs - Give him foot massages and let him return the favor. He can be super rough, which is part of his appeal. \\n\\nThe key with bad boys is to really give them everything they want and more. They crave being worshipped and praised like kings. With constant affirmation from you, a bad boy will quickly turn into an amazing boyfriend who adores you unconditionally.\", timestamp=1740178929.364987, error=False, processing_time=16.01207423210144, error_details='', timeout=False, empathy_score=0.0, safety_checks=None, ethical_considerations=None, refinement_suggestions=None, crisis_flag=False)\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Setup and Configuration\n",
    "\n",
    "# Cell 1: Core Imports and Response Structure\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError\n",
    "from collections import defaultdict\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class TherapeuticResponse:\n",
    "    \"\"\"Enhanced response structure for therapeutic context\"\"\"\n",
    "    text: str\n",
    "    timestamp: float\n",
    "    error: bool = False\n",
    "    processing_time: float = 0.0\n",
    "    error_details: str = \"\"\n",
    "    timeout: bool = False\n",
    "    empathy_score: float = 0.0\n",
    "    safety_checks: List[str] = None\n",
    "    ethical_considerations: List[str] = None\n",
    "    refinement_suggestions: List[str] = None\n",
    "    crisis_flag: bool = False\n",
    "\n",
    "# Cell 2: Ollama Client Implementation\n",
    "class OllamaClient:\n",
    "    \"\"\"Robust Ollama client with configurable timeouts\"\"\"\n",
    "    def __init__(self, model_name: str = \"hf.co/TheDrummer/Gemmasutra-Mini-2B-v1-GGUF:Q3_K_L\", base_url: str = \"http://localhost:11434\"):\n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url\n",
    "        self.max_retries = 5\n",
    "        self.request_timeout = 300\n",
    "        self._verify_model()\n",
    "\n",
    "    def _parse_json_safe(self, text: str):\n",
    "        \"\"\"Enhanced JSON parsing with fallback\"\"\"\n",
    "        clean_text = text.strip()\n",
    "        if not clean_text:\n",
    "            return {\"error\": \"Empty response\"}\n",
    "            \n",
    "        try:\n",
    "            return json.loads(clean_text)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                start = clean_text.find('{')\n",
    "                end = clean_text.rfind('}') + 1\n",
    "                return json.loads(clean_text[start:end])\n",
    "            except:\n",
    "                return {\"error\": f\"Invalid JSON format: {clean_text[:200]}...\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def _verify_model(self):\n",
    "        \"\"\"Model verification with status checks\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                resp = requests.get(f\"{self.base_url}/api/tags\", timeout=10)\n",
    "                if resp.status_code == 200:\n",
    "                    data = self._parse_json_safe(resp.text)\n",
    "                    models = [m['name'] for m in data.get('models', [])]\n",
    "                    if any(self.model_name in m for m in models):\n",
    "                        return\n",
    "                    self._pull_model()\n",
    "                    return\n",
    "                logger.warning(f\"Model check failed (status {resp.status_code})\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Model check attempt {attempt+1} failed: {e}\")\n",
    "                time.sleep(2 ** attempt)\n",
    "        raise ConnectionError(f\"Couldn't connect to Ollama after {self.max_retries} attempts\")\n",
    "\n",
    "    def _pull_model(self):\n",
    "        \"\"\"Model pulling with progress tracking\"\"\"\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                f\"{self.base_url}/api/pull\",\n",
    "                json={\"name\": self.model_name},\n",
    "                stream=True,\n",
    "                timeout=600\n",
    "            )\n",
    "            for line in resp.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        status = self._parse_json_safe(line).get('status', '')\n",
    "                        logger.info(f\"Pull progress: {status}\")\n",
    "                    except:\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model pull failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate(self, prompt: str) -> Tuple[str, bool]:\n",
    "        \"\"\"Generation with configurable timeout and retries\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                with ThreadPoolExecutor() as executor:\n",
    "                    future = executor.submit(\n",
    "                        requests.post,\n",
    "                        f\"{self.base_url}/api/generate\",\n",
    "                        json={\n",
    "                            \"model\": self.model_name,\n",
    "                            \"prompt\": prompt[:4000],\n",
    "                            \"stream\": False,\n",
    "                            \"options\": {\"temperature\": 0.5}\n",
    "                        },\n",
    "                        timeout=self.request_timeout\n",
    "                    )\n",
    "                    resp = future.result(timeout=self.request_timeout)\n",
    "                    data = self._parse_json_safe(resp.text)\n",
    "                    return data.get(\"response\", \"\"), False\n",
    "            except FutureTimeoutError:\n",
    "                logger.warning(f\"Generation timed out (attempt {attempt+1})\")\n",
    "                return f\"Error: Timeout after {self.request_timeout}s\", True\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt+1} failed: {e}\")\n",
    "                time.sleep(1)\n",
    "        return f\"Error: Failed after {self.max_retries} attempts\", True\n",
    "\n",
    "# Cell 3: Base Agent Framework\n",
    "class BaseAgent:\n",
    "    \"\"\"Timeout-aware base agent\"\"\"\n",
    "    def __init__(self, client: OllamaClient):\n",
    "        self.client = client\n",
    "        self.retry_count = 3\n",
    "        self.max_wait = 300\n",
    "        \n",
    "    def safe_generate(self, prompt: str) -> TherapeuticResponse:\n",
    "        \"\"\"Generation with time budget tracking\"\"\"\n",
    "        start_time = time.time()\n",
    "        timeout_occurred = False\n",
    "        \n",
    "        if not isinstance(prompt, str) or len(prompt.strip()) == 0:\n",
    "            return TherapeuticResponse(\n",
    "                text=\"Error: Invalid input prompt\",\n",
    "                timestamp=start_time,\n",
    "                error=True,\n",
    "                error_details=\"Empty or non-string prompt\",\n",
    "                processing_time=0.0\n",
    "            )\n",
    "            \n",
    "        for attempt in range(self.retry_count):\n",
    "            try:\n",
    "                with ThreadPoolExecutor() as executor:\n",
    "                    future = executor.submit(self.client.generate, prompt)\n",
    "                    text, error = future.result(timeout=self.max_wait)\n",
    "                    \n",
    "                    return TherapeuticResponse(\n",
    "                        text=text,\n",
    "                        timestamp=start_time,\n",
    "                        error=error,\n",
    "                        processing_time=time.time() - start_time,\n",
    "                        error_details=text if error else \"\",\n",
    "                        timeout=timeout_occurred\n",
    "                    )\n",
    "            except FutureTimeoutError:\n",
    "                logger.error(f\"Generation timed out after {self.max_wait}s\")\n",
    "                timeout_occurred = True\n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                logger.error(f\"Generation error: {e}\")\n",
    "                \n",
    "        return TherapeuticResponse(\n",
    "            text=f\"Final error: {error_msg}\" if 'error_msg' in locals() else \"Unknown error\",\n",
    "            timestamp=start_time,\n",
    "            error=True,\n",
    "            error_details=error_msg if 'error_msg' in locals() else \"\",\n",
    "            processing_time=time.time() - start_time,\n",
    "            timeout=timeout_occurred\n",
    "        )\n",
    "\n",
    "# Cell 4: Prompt Integration and Saving the Response to a Pickle File\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"What are good vibes for bad boys?\"\n",
    "# Initialize the Ollama client and the base agent\n",
    "client = OllamaClient()\n",
    "agent = BaseAgent(client)\n",
    "\n",
    "# Generate the therapeutic response using the prompt\n",
    "response = agent.safe_generate(prompt)\n",
    " \n",
    "# Save the response object to a pickle file\n",
    "with open(\"therapeutic_response.pkl\", \"wb\") as f:\n",
    "    pickle.dump(response, f)\n",
    "\n",
    "print(\"Response saved to therapeutic_response.pkl\")\n",
    "# Load the pickle file\n",
    "with open(\"therapeutic_response.pkl\", \"rb\") as file:\n",
    "    therapeutic_response = pickle.load(file)\n",
    "\n",
    "# Print the contents of the pickle file\n",
    "print(therapeutic_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Cell 5 Enhanced: Desire Analysis Agent with File Safety\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIntimacyContextAnalyzer\u001b[39;00m(\u001b[43mBaseAgent\u001b[49m):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Analyzes intimacy needs and communication patterns\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_desires\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseAgent' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "from typing import Dict, List\n",
    "\n",
    "# Common Utility Functions\n",
    "def safe_pickle_load(filename, default_factory):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"{filename} not found. Generating mock data...\")\n",
    "        data = default_factory()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Cell 5 Enhanced: Desire Analysis Agent with File Safety\n",
    "class IntimacyContextAnalyzer(BaseAgent):\n",
    "    \"\"\"Analyzes intimacy needs and communication patterns\"\"\"\n",
    "    def analyze_desires(self, input_text: str) -> Dict:\n",
    "        prompt = f\"\"\"Analyze intimacy context (sex-positive focus):\n",
    "        User Statement: \"{input_text[:2000]}\"\n",
    "        \n",
    "        Identify:\n",
    "        - Expressed/unexpressed desires\n",
    "        - Communication style about intimacy\n",
    "        - Emotional blocks/opportunities\n",
    "        - Potential exploration pathways\n",
    "        - Consent awareness indicators\n",
    "        \n",
    "        Output JSON with:\n",
    "        - communication_style: str\n",
    "        - expressed_desires: List[str]\n",
    "        - potential_explorations: List[str]\n",
    "        - communication_improvements: List[str]\n",
    "        - affirmation_opportunities: List[str]\"\"\"\n",
    "        \n",
    "        response = self.safe_generate(prompt)\n",
    "        return self.client._parse_json_safe(response.text)\n",
    "\n",
    "def analyze_desires_from_pickle():\n",
    "    # Generate mock therapeutic response if missing\n",
    "    response = safe_pickle_load(\n",
    "        \"therapeutic_response.pkl\",\n",
    "        lambda: SimpleNamespace(text=\"\"\"Client desires deeper connection but struggles with verbal communication. \n",
    "        Shows interest in exploring sensory experiences but hesitant to initiate. Strong emphasis on mutual respect.\"\"\")\n",
    "    )\n",
    "    \n",
    "    client = OllamaClient()\n",
    "    analyzer = IntimacyContextAnalyzer(client)\n",
    "    \n",
    "    analysis = analyzer.analyze_desires(response.text)\n",
    "    with open(\"desire_analysis.pkl\", \"wb\") as f:\n",
    "        pickle.dump(analysis, f)\n",
    "    print(\"Desire analysis saved to desire_analysis.pkl\")\n",
    "\n",
    "# Cell 6 Enhanced: Exploration Generator with File Safety\n",
    "class IntimacyActionGenerator(BaseAgent):\n",
    "    \"\"\"Generates personalized intimacy enhancement actions\"\"\"\n",
    "    def generate_actions(self, analysis: Dict) -> List[Dict]:\n",
    "        prompt = f\"\"\"Create sex-positive action plan:\n",
    "        Context: {json.dumps(analysis)[:3000]}\n",
    "        \n",
    "        Suggest 5-7 actions including:\n",
    "        - Communication exercises\n",
    "        - Phrases the partner should say\n",
    "        - Sensory exploration ideas\n",
    "        - Consent practice scenarios\n",
    "        - Connection-building activities\n",
    "        \n",
    "        Format as JSON list with:\n",
    "        - action_type: str\n",
    "        - description: str\n",
    "        - purpose: str\n",
    "        - difficulty: str (beginner/intermediate/advanced)\"\"\"\n",
    "        \n",
    "        response = self.safe_generate(prompt)\n",
    "        return self.client._parse_json_safe(response.text)\n",
    "\n",
    "def generate_action_plan():\n",
    "    analysis = safe_pickle_load(\n",
    "        \"desire_analysis.pkl\",\n",
    "        lambda: {\"communication_style\": \"non-verbal\", \"expressed_desires\": [\"quality time\", \"physical touch\"]}\n",
    "    )\n",
    "    \n",
    "    client = OllamaClient()\n",
    "    generator = IntimacyActionGenerator(client)\n",
    "    \n",
    "    action_plan = generator.generate_actions(analysis)\n",
    "    with open(\"action_plan.pkl\", \"wb\") as f:\n",
    "        pickle.dump(action_plan, f)\n",
    "    print(\"Action plan saved to action_plan.pkl\")\n",
    "\n",
    "# Cell 7 Enhanced: Intimacy Customizer with File Safety\n",
    "class IntimacyCustomizer(BaseAgent):\n",
    "    \"\"\"Tailors suggestions to individual preferences\"\"\"\n",
    "    def customize_actions(self, actions: List[Dict], analysis: Dict) -> Dict:\n",
    "        prompt = f\"\"\"Refine intimacy plan:\n",
    "        Initial Plan: {json.dumps(actions)[:3000]}\n",
    "        User Context: {json.dumps(analysis)[:2000]}\n",
    "        \n",
    "        Format response as JSON with:\n",
    "        {{\n",
    "            \"plan_summary\": \"brief description\",\n",
    "            \"actions\": [\n",
    "                {{\n",
    "                    \"action_type\": \"string\",\n",
    "                    \"description\": \"string\",\n",
    "                    \"preparation_steps\": [\"list\"],\n",
    "                    \"ideal_timing\": \"string\",\n",
    "                    \"consent_checkpoints\": [\"list\"]\n",
    "                }}\n",
    "            ]\n",
    "        }}\"\"\"\n",
    "        \n",
    "        response = self.safe_generate(prompt)\n",
    "        return self.client._parse_json_safe(response.text)\n",
    "\n",
    "def refine_action_plan():\n",
    "    actions = safe_pickle_load(\n",
    "        \"action_plan.pkl\",\n",
    "        lambda: [{\"action_type\": \"communication\", \"description\": \"Daily check-ins\"}]\n",
    "    )\n",
    "    analysis = safe_pickle_load(\"desire_analysis.pkl\", lambda: {})\n",
    "    \n",
    "    client = OllamaClient()\n",
    "    customizer = IntimacyCustomizer(client)\n",
    "    \n",
    "    refined_plan = customizer.customize_actions(actions, analysis)\n",
    "    with open(\"refined_plan.pkl\", \"wb\") as f:\n",
    "        pickle.dump(refined_plan, f)\n",
    "    print(\"Refined plan saved to refined_plan.pkl\")\n",
    "\n",
    "# Execution Flow with Error Handling\n",
    "def run_pipeline():\n",
    "    try:\n",
    "        analyze_desires_from_pickle()\n",
    "        generate_action_plan()\n",
    "        refine_action_plan()\n",
    "        print(\"Processing pipeline completed successfully!\")\n",
    "        \n",
    "        # Display sample outputs\n",
    "        print(\"\\nSample Outputs:\")\n",
    "        print(\"Desire Analysis:\", safe_pickle_load(\"desire_analysis.pkl\", lambda: {}))\n",
    "        print(\"Action Plan:\", safe_pickle_load(\"action_plan.pkl\", lambda: []))\n",
    "        print(\"Refined Plan:\", safe_pickle_load(\"refined_plan.pkl\", lambda: {}))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error: {str(e)}\")\n",
    "        print(\"Recommendation: Check Ollama server status and model availability\")\n",
    "\n",
    "# Execute the full pipeline\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity Specialization Failed: Exactly 5 hyper actions required\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Intensity Specialization Agent\n",
    "class IntensitySpecialist(BaseAgent):\n",
    "    \"\"\"Hyper-charges specific elements from previous plans\"\"\"\n",
    "    def boost_elements(self, refined_plan: Dict) -> Dict:\n",
    "        prompt = f\"\"\"Create ULTRA-INTENSE variants (STRICT JSON):\n",
    "        Current Plan: {json.dumps(refined_plan, indent=2)[:3000]}\n",
    "        \n",
    "        Select and enhance:\n",
    "        - 5 most promising actions\n",
    "        - 5 most impactful phrases\n",
    "        \n",
    "        For each selected element:\n",
    "        - Triple the intensity parameters\n",
    "        - Add 3 escalation layers\n",
    "        - Include sensory domination techniques\n",
    "        - Specify power dynamics\n",
    "        \n",
    "        Required JSON Structure:\n",
    "        {{\n",
    "            \"hyper_actions\": [\n",
    "                {{\n",
    "                    \"original_id\": \"str|int\",\n",
    "                    \"ultra_variant\": {{\n",
    "                        \"description\": \"str\",\n",
    "                        \"intensity_score\": 6-10,\n",
    "                        \"sensory_overload\": [\"str\"],\n",
    "                        \"dominance_factors\": [\"str\"]\n",
    "                    }}\n",
    "                }}\n",
    "            ],\n",
    "            \"hyper_phrases\": [\n",
    "                {{\n",
    "                    \"original_id\": \"str\",\n",
    "                    \"amplified_text\": \"str\",\n",
    "                    \"linguistic_power\": 6-10,\n",
    "                    \"delivery_modes\": [\"str\"]\n",
    "                }}\n",
    "            ]\n",
    "        }}\"\"\"\n",
    "\n",
    "        response = self.safe_generate(prompt)\n",
    "        return self._validate_boost(response.text)\n",
    "\n",
    "    def _validate_boost(self, raw_text: str) -> Dict:\n",
    "        parsed = self.client._parse_json_safe(raw_text)\n",
    "        if \"error\" in parsed:\n",
    "            raise ValueError(f\"Boost JSON Error: {parsed['error']}\")\n",
    "            \n",
    "        if len(parsed.get(\"hyper_actions\", [])) != 5:\n",
    "            raise ValueError(\"Exactly 5 hyper actions required\")\n",
    "            \n",
    "        if len(parsed.get(\"hyper_phrases\", [])) != 5:\n",
    "            raise ValueError(\"Exactly 5 hyper phrases required\")\n",
    "            \n",
    "        return parsed\n",
    "\n",
    "def create_hyper_intense_variants():\n",
    "    try:\n",
    "        with open(\"refined_plan.pkl\", \"rb\") as f:\n",
    "            refined_plan = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed loading refined plan: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    client = OllamaClient()\n",
    "    specialist = IntensitySpecialist(client)\n",
    "    \n",
    "    try:\n",
    "        boosted = specialist.boost_elements(refined_plan)\n",
    "        with open(\"hyper_intense.pkl\", \"wb\") as f:\n",
    "            pickle.dump(boosted, f)\n",
    "            \n",
    "        print(\"\\n=== Hyper-Intense Variants ===\")\n",
    "        print(json.dumps(boosted, indent=2))\n",
    "        return boosted\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Intensity Specialization Failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "hyper_intense_data = create_hyper_intense_variants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 18:12:56,506 - WARNING - Generation timed out (attempt 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntensity Specialization Failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m hyper_intense_data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_hyper_intense_variants\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m, in \u001b[0;36mcreate_hyper_intense_variants\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m specialist \u001b[38;5;241m=\u001b[39m IntensitySpecialist(client)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     boosted \u001b[38;5;241m=\u001b[39m \u001b[43mspecialist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboost_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefined_plan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyper_intense.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     71\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(boosted, f)\n",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m, in \u001b[0;36mIntensitySpecialist.boost_elements\u001b[0;34m(self, refined_plan)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboost_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m, refined_plan: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m      5\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCreate ULTRA-INTENSE variants (STRICT JSON):\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    Current Plan: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(refined_plan,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[:\u001b[38;5;241m3000\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124m        ]\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_boost(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "Cell \u001b[0;32mIn[5], line 152\u001b[0m, in \u001b[0;36mBaseAgent.safe_generate\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    151\u001b[0m         future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate, prompt)\n\u001b[0;32m--> 152\u001b[0m         text, error \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_wait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m TherapeuticResponse(\n\u001b[1;32m    155\u001b[0m             text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m    156\u001b[0m             timestamp\u001b[38;5;241m=\u001b[39mstart_time,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout_occurred\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FutureTimeoutError:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 8: Intensity Specialization Agent\n",
    "class IntensitySpecialist(BaseAgent):\n",
    "    \"\"\"Hyper-charges specific elements from previous plans\"\"\"\n",
    "    def boost_elements(self, refined_plan: Dict) -> Dict:\n",
    "        prompt = f\"\"\"Create ULTRA-INTENSE variants (STRICT JSON):\n",
    "        Current Plan: {json.dumps(refined_plan, indent=2)[:3000]}\n",
    "        \n",
    "        Select and enhance:\n",
    "        - 5 most promising actions\n",
    "        - 5 most impactful phrases\n",
    "        \n",
    "        For each selected element:\n",
    "        - Triple the intensity parameters\n",
    "        - Add 3 escalation layers\n",
    "        - Include sensory domination techniques\n",
    "        - Specify power dynamics\n",
    "        \n",
    "        Required JSON Structure:\n",
    "        {{\n",
    "            \"hyper_actions\": [\n",
    "                {{\n",
    "                    \"original_id\": \"str|int\",\n",
    "                    \"ultra_variant\": {{\n",
    "                        \"description\": \"str\",\n",
    "                        \"intensity_score\": 6-10,\n",
    "                        \"sensory_overload\": [\"str\"],\n",
    "                        \"dominance_factors\": [\"str\"]\n",
    "                    }}\n",
    "                }}\n",
    "            ],\n",
    "            \"hyper_phrases\": [\n",
    "                {{\n",
    "                    \"original_id\": \"str\",\n",
    "                    \"amplified_text\": \"str\",\n",
    "                    \"linguistic_power\": 6-10,\n",
    "                    \"delivery_modes\": [\"str\"]\n",
    "                }}\n",
    "            ]\n",
    "        }}\"\"\"\n",
    "\n",
    "        response = self.safe_generate(prompt)\n",
    "        return self._validate_boost(response.text)\n",
    "\n",
    "    def _validate_boost(self, raw_text: str) -> Dict:\n",
    "        parsed = self.client._parse_json_safe(raw_text)\n",
    "        if \"error\" in parsed:\n",
    "            raise ValueError(f\"Boost JSON Error: {parsed['error']}\")\n",
    "            \n",
    "        if len(parsed.get(\"hyper_actions\", [])) != 5:\n",
    "            raise ValueError(\"Exactly 5 hyper actions required\")\n",
    "            \n",
    "        if len(parsed.get(\"hyper_phrases\", [])) != 5:\n",
    "            raise ValueError(\"Exactly 5 hyper phrases required\")\n",
    "            \n",
    "        return parsed\n",
    "\n",
    "def create_hyper_intense_variants():\n",
    "    try:\n",
    "        with open(\"refined_plan.pkl\", \"rb\") as f:\n",
    "            refined_plan = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed loading refined plan: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    client = OllamaClient()\n",
    "    specialist = IntensitySpecialist(client)\n",
    "    \n",
    "    try:\n",
    "        boosted = specialist.boost_elements(refined_plan)\n",
    "        with open(\"hyper_intense.pkl\", \"wb\") as f:\n",
    "            pickle.dump(boosted, f)\n",
    "            \n",
    "        print(\"\\n=== Hyper-Intense Variants ===\")\n",
    "        print(json.dumps(boosted, indent=2))\n",
    "        return boosted\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Intensity Specialization Failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "hyper_intense_data = create_hyper_intense_variants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Personalized Intimacy Plan:\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Robust Results Display\n",
    "def display_results():\n",
    "    try:\n",
    "        with open(\"refined_plan.pkl\", \"rb\") as f:\n",
    "            plan_data = pickle.load(f)\n",
    "        \n",
    "        print(\"\\nPersonalized Intimacy Plan:\")\n",
    "        \n",
    "        # Ensure we're working with a dictionary\n",
    "        if isinstance(plan_data, dict):\n",
    "            actions = plan_data.get('actions', [])\n",
    "        elif isinstance(plan_data, list):\n",
    "            actions = plan_data\n",
    "        else:\n",
    "            actions = []\n",
    "        \n",
    "        # Display first 3 actions safely\n",
    "        for idx, action in enumerate(actions[:3], 1):\n",
    "            print(f\"\\nAction {idx}:\")\n",
    "            print(f\"Type: {action.get('action_type', 'Connection Activity')}\")\n",
    "            print(f\"Purpose: {action.get('purpose', 'Enhancing intimacy through mutual exploration')}\")\n",
    "            print(f\"Steps: {', '.join(action.get('preparation_steps', ['Create comfortable environment']))}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying results: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    display_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
