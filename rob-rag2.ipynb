{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (0.3.14)\n",
      "Requirement already satisfied: huggingface_hub in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (0.26.2)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (0.42.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (3.11.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from bitsandbytes) (1.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/6ydqkbq172ngzt6p49xfm6b00000gn/T/ipykernel_7408/397498250.py:50: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "No sentence-transformers model found with name roberta-base. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 150 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/6ydqkbq172ngzt6p49xfm6b00000gn/T/ipykernel_7408/397498250.py:99: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-Neo 125M model loaded successfully.\n",
      "Chatbot initialized. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/6ydqkbq172ngzt6p49xfm6b00000gn/T/ipykernel_7408/397498250.py:153: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Assistant: the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a beautiful thing but the beauty is a\n",
      "\n",
      "Top Sources:\n",
      "1. 115 focus on what blinds you with its beauty brilliance and feeling focus on the illest things and be set free again update 21919 daaaaamn but what if... (Score: 0.00)\n",
      "2. 128 particles omg higgs boson the standard model of particle physics cern quarks the movie particle fever gev dark matter its also so fascinating the ... (Score: 0.00)\n",
      "3. 127 satisfaction a does real health love wisdomknowledge matter to you b then be satisfied by what you think satisfies you this marks the beginningof ... (Score: 0.00)\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "Please enter a valid question\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# works responses not great - better rag needed\n",
    "# Install required packages\n",
    "!pip install langchain huggingface_hub pandas faiss-cpu numpy transformers torch accelerate bitsandbytes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "def load_embeddings(csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Verify required columns exist\n",
    "        if 'Cleaned_Ideas' not in df.columns or 'Embeddings' not in df.columns:\n",
    "            raise ValueError(\"CSV must contain 'Cleaned_Ideas' and 'Embeddings' columns\")\n",
    "            \n",
    "        # Convert embeddings with proper handling\n",
    "        df['Embeddings'] = df['Embeddings'].apply(\n",
    "            lambda x: np.fromstring(\n",
    "                x.strip(\"[]\").replace(\"\\n\", \"\"),\n",
    "                sep=\", \",\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Validate embedding dimensions (RoBERTa-base has 768 dimensions)\n",
    "        expected_dim = 768\n",
    "        valid_embeddings = df['Embeddings'].apply(lambda x: len(x) == expected_dim)\n",
    "        if not valid_embeddings.all():\n",
    "            invalid_count = len(df) - valid_embeddings.sum()\n",
    "            raise ValueError(f\"{invalid_count} entries have invalid embedding dimensions\")\n",
    "            \n",
    "        return df['Cleaned_Ideas'].tolist(), np.array(df['Embeddings'].tolist())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embeddings: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 1. Load texts and embeddings from CSV\n",
    "texts, embeddings = load_embeddings(\"ideas_with_embeddings.csv\")\n",
    "\n",
    "# 2. Create FAISS vector store using a Hugging Face embedding model (using roberta-base)\n",
    "try:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=\"roberta-base\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        # Removed \"show_progress_bar\" to avoid duplicate parameter issues.\n",
    "        encode_kwargs={'normalize_embeddings': False}\n",
    "    )\n",
    "    \n",
    "    # Create FAISS index; each entry is a tuple (text, embedding)\n",
    "    vector_store = FAISS.from_embeddings(\n",
    "        text_embeddings=list(zip(texts, embeddings)),\n",
    "        embedding=embedding_model,\n",
    "        normalize_L2=True  # Improves cosine similarity calculations\n",
    "    )\n",
    "    print(f\"FAISS index created with {vector_store.index.ntotal} entries\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Vector store creation failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# 3. Load a smaller Hugging Face model in safetensors format (EleutherAI/gpt-neo-125M)\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "try:\n",
    "    # For a smaller model, we typically use full precision\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"GPT-Neo 125M model loaded successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Model loading failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create the text-generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    do_sample=True,\n",
    "    return_full_text=False,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 4. Define a custom prompt template\n",
    "template = \"\"\"### Instruction:\n",
    "Analyze this philosophical concept using the provided context. \n",
    "If unsure, state \"I don't have sufficient information.\"\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template_format=\"f-string\"\n",
    ")\n",
    "\n",
    "# 5. Set up a Production-grade Retrieval QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5, \"score_threshold\": 0.4}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt,\n",
    "        \"document_prompt\": PromptTemplate(\n",
    "            input_variables=[\"page_content\"],\n",
    "            template=\"{page_content}\"\n",
    "        )\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 6. Enhanced chat interface for interactive querying\n",
    "def run_chat():\n",
    "    print(\"Chatbot initialized. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nUser: \").strip()\n",
    "            if query.lower() in [\"exit\", \"quit\"]:\n",
    "                break\n",
    "                \n",
    "            if not query:\n",
    "                print(\"Please enter a valid question\")\n",
    "                continue\n",
    "                \n",
    "            result = qa_chain({\"query\": query})\n",
    "            \n",
    "            # Process the response\n",
    "            response = result['result'].split(\"### Assistant Response:\")[-1].strip()\n",
    "            print(f\"\\nAssistant: {response}\")\n",
    "            \n",
    "            # Display top source excerpts\n",
    "            print(\"\\nTop Sources:\")\n",
    "            for i, doc in enumerate(result['source_documents'][:3], 1):\n",
    "                excerpt = doc.page_content[:150].replace(\"\\n\", \" \") + \"...\"\n",
    "                score = doc.metadata.get('score', 0)\n",
    "                print(f\"{i}. {excerpt} (Score: {score:.2f})\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nExiting chat.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing request: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
